{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGbNNNXV9nkYWgWZVnVv+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AniketGaudgaul/AI-ML-DL_Projects/blob/main/SC3_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cbBTkq8svo1"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download aseemdandgaval/23-pet-breeds-image-classification\n",
        "!unzip /content/23-pet-breeds-image-classification.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Set the input path and target size for the images\n",
        "input_folder = '/content/Pet_Breeds'\n",
        "\n",
        "# Loop through all the folders in the input folder\n",
        "for i, folder_name in enumerate(os.listdir(input_folder)):\n",
        "    folder_path = os.path.join(input_folder, folder_name)\n",
        "\n",
        "    # Loop through all the files in the folder\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "        # Open the image and resize it\n",
        "        with Image.open(file_path) as image:\n",
        "            if image.mode not in ('RGB', 'RGBA'):\n",
        "                image = image.convert('RGB')\n",
        "            if image.mode == 'RGBA':\n",
        "                image = image.convert('RGB')\n",
        "\n"
      ],
      "metadata": {
        "id": "rf1e_2xyzKrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "input_folder = '/content/Pet_Breeds'\n",
        "target_size = (224, 224)\n",
        "batch_size = 50\n",
        "\n",
        "# Create an instance of the ImageDataGenerator class for training and validation data with data augmentation\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=10, # randomly rotate images up to 20 degrees\n",
        "    width_shift_range=0.1, # randomly shift images horizontally by up to 10% of the image width\n",
        "    height_shift_range=0.1, # randomly shift images vertically by up to 10% of the image height\n",
        "    zoom_range=0.1, # randomly zoom images by up to 10%\n",
        "    horizontal_flip=True # randomly flip images horizontally\n",
        ")\n",
        "\n",
        "# Load the training data with data augmentation\n",
        "train_data = data_generator.flow_from_directory(\n",
        "    input_folder,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Load the validation data without data augmentation\n",
        "val_data = data_generator.flow_from_directory(\n",
        "    input_folder,\n",
        "    target_size=target_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "\n",
        "# Get the class indices from the data generator\n",
        "class_indices = train_data.class_indices\n",
        "\n",
        "# Reverse the class indices dictionary to get a dictionary of breed names to indices\n",
        "breed_to_index = dict((v,k) for k,v in class_indices.items())\n",
        "\n",
        "# Use the breed_to_index dictionary to get a list of the breed names for each image in the training and validation sets\n",
        "train_breeds = [breed_to_index[np.argmax(train_data[i][1])] for i in range(len(train_data))]\n",
        "val_breeds = [breed_to_index[np.argmax(val_data[i][1])] for i in range(len(val_data))]\n",
        "\n",
        "# Convert the list of breeds to numpy arrays\n",
        "train_breeds = np.array(train_breeds)\n",
        "val_breeds = np.array(val_breeds)\n",
        "\n",
        "# Print the shape of the arrays\n",
        "print(\"Training breeds shape:\", train_breeds.shape)\n",
        "print(\"Validation breeds shape:\", val_breeds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1V_cN-GzMof",
        "outputId": "f58ac072-2141-4ea5-d414-a05965ca2f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3105 images belonging to 23 classes.\n",
            "Found 776 images belonging to 23 classes.\n",
            "Training breeds shape: (63,)\n",
            "Validation breeds shape: (16,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "\n",
        "# Define the input shape for the MobileNet model\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Load the MobileNet model, pre-trained on ImageNet\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Freeze the pre-trained layers of the model so they are not updated during training\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model on top of the pre-trained model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(23, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "gbgnXZ98zZl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data, epochs=3, validation_data=val_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-pib8oXzb94",
        "outputId": "3d0ae673-72ca-4eda-8d3c-f252a63ba6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "63/63 [==============================] - 166s 2s/step - loss: 0.9329 - accuracy: 0.7314 - val_loss: 0.6829 - val_accuracy: 0.8028\n",
            "Epoch 2/3\n",
            "63/63 [==============================] - 147s 2s/step - loss: 0.4008 - accuracy: 0.8699 - val_loss: 0.8300 - val_accuracy: 0.7938\n",
            "Epoch 3/3\n",
            "63/63 [==============================] - 135s 2s/step - loss: 0.3085 - accuracy: 0.9011 - val_loss: 0.4803 - val_accuracy: 0.8505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the image\n",
        "img_path = '/content/mainecoon.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Preprocess the image\n",
        "img_array /= 255.\n",
        "\n",
        "# Make a prediction\n",
        "prediction = model.predict(img_array)\n",
        "\n",
        "# Get the predicted breed\n",
        "predicted_breed = breed_to_index[np.argmax(prediction)]\n",
        "\n",
        "# Print the predicted breed\n",
        "print(\"Predicted breed:\", predicted_breed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bu1Z_qt-fm7",
        "outputId": "ab587686-6a92-49d6-ffa9-3286b6f2b4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Predicted breed: maine coon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "model.save('my_pet_breeds_MobileNet.h5')\n"
      ],
      "metadata": {
        "id": "q-e802TF-6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/my_pet_breeds_MobileNet.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "I1nSP1a6_obi",
        "outputId": "9cafada0-049c-464a-afd8-572a8ad482a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_14423d11-d43b-4ab8-9df4-5e4be017b328\", \"my_pet_breeds_MobileNet.h5\", 13356072)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-Weyssq_r2_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}